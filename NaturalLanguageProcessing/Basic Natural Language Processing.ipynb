{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1> Basic Natural Language Processing\n",
    "</center>\n",
    "\n",
    "###### Basic Sentiment analysis on Movie dataset. This dataset is available at Kaggle and provided by University of Michigan.\n",
    "###### https://www.kaggle.com/c/si650winter11/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Da Vinci Code book is just awesome.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this was the first clive cussler i've ever rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I liked the Da Vinci Code but it ultimatly did...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          1            The Da Vinci Code book is just awesome.\n",
       "1          1  this was the first clive cussler i've ever rea...\n",
       "2          1                   i liked the Da Vinci Code a lot.\n",
       "3          1                   i liked the Da Vinci Code a lot.\n",
       "4          1  I liked the Da Vinci Code but it ultimatly did..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sentitraindf = pd.read_csv('sentiment_train.csv',delimiter='\\t')\n",
    "sentitraindf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pre-processing\n",
    "\n",
    "###### BoW (Bag of Words) Model \n",
    "\n",
    "###### Method-1 : Count Vector\n",
    "\n",
    "###### Note 1 : Create dictionary corpus across all documents. The documents will be represented by number of times each word appears in the document.\n",
    "###### Note 2 : Observe the F-string literal used for printing text. This comes in handy for formatting text and display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 2132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "identifiedfeatures_vector = count_vectorizer.fit(sentitraindf.text)\n",
    "\n",
    "identifiedfeatures = identifiedfeatures_vector.get_feature_names()\n",
    "numberoffeatures = len(identifiedfeatures)\n",
    "print(f\"Total number of features: {numberoffeatures}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform documents into vectors using transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6918, 2132)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_identifiedfeatures = count_vectorizer.transform(sentitraindf.text)\n",
    "train_identifiedfeatures.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Matrix checking\n",
    "\n",
    "#### Sparse Matrix occurs if there are high proprotion of zeros in comparison to non-zero values in the resultant matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzerovals = train_identifiedfeatures.getnnz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density of the matrix: 0.4434010415225908\n"
     ]
    }
   ],
   "source": [
    "density = nonzerovals*100/(train_identifiedfeatures.shape[0]*train_identifiedfeatures.shape[1])\n",
    "print(f\"Density of the matrix: {density}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above mentioned density matrix has less than 1% non-zero values and is a very sparse matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Frequency of the features column-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>the</td>\n",
       "      <td>3306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>and</td>\n",
       "      <td>2154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>harry</td>\n",
       "      <td>2093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>potter</td>\n",
       "      <td>2093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>code</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>vinci</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>da</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>mountain</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>brokeback</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>love</td>\n",
       "      <td>1624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>is</td>\n",
       "      <td>1520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>was</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>awesome</td>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>mission</td>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>impossible</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>like</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>it</td>\n",
       "      <td>901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>to</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>movie</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>that</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>because</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>sucks</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>sucked</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>hate</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>so</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        features  counts\n",
       "1864         the    3306\n",
       "93           and    2154\n",
       "864        harry    2093\n",
       "1466      potter    2093\n",
       "355         code    2002\n",
       "2009       vinci    2001\n",
       "442           da    2001\n",
       "1272    mountain    2000\n",
       "259    brokeback    2000\n",
       "1171        love    1624\n",
       "1018          is    1520\n",
       "2029         was    1176\n",
       "151      awesome    1127\n",
       "1252     mission    1094\n",
       "977   impossible    1093\n",
       "1132        like     974\n",
       "1022          it     901\n",
       "1916          to     808\n",
       "1275       movie     783\n",
       "1862        that     719\n",
       "189      because     608\n",
       "1805       sucks     602\n",
       "1803      sucked     600\n",
       "867         hate     578\n",
       "1725          so     506"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_counts = np.sum(train_identifiedfeatures.toarray(),axis=0)\n",
    "\n",
    "featurescountdf = pd.DataFrame(dict(features=identifiedfeatures, counts = features_counts))\n",
    "featurescountdf.sort_values('counts',ascending= False)[0:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Removing Stop Words (i.e most common words used in a language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "stop_words_for_my_usecase = text.ENGLISH_STOP_WORDS.union(['movie','movies','harry','potter','da'\n",
    "                                                  ,'vinci','code','brokeback','mountain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>love</td>\n",
       "      <td>1624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>awesome</td>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>mission</td>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>impossible</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>like</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>sucks</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>sucked</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>hate</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>really</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>stupid</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       features  counts\n",
       "407        love    1624\n",
       "39      awesome    1127\n",
       "435     mission    1094\n",
       "340  impossible    1093\n",
       "389        like     974\n",
       "744       sucks     602\n",
       "742      sucked     600\n",
       "296        hate     578\n",
       "651      really     374\n",
       "740      stupid     365"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words=stop_words_for_my_usecase,max_features=1000)\n",
    "\n",
    "identifiedfeatures_vector = count_vectorizer.fit(sentitraindf.text)\n",
    "train_identifiedfeatures = count_vectorizer.transform(sentitraindf.text)\n",
    "identifiedfeatures = identifiedfeatures_vector.get_feature_names()\n",
    "features_counts = np.sum(train_identifiedfeatures.toarray(),axis=0)\n",
    "\n",
    "featurescountdf = pd.DataFrame(dict(features=identifiedfeatures, counts = features_counts))\n",
    "featurescountdf.sort_values('counts',ascending= False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting words into root words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_for_my_usecase = text.ENGLISH_STOP_WORDS.union(['movie','movies','harry','potter','da'\n",
    "                                                  ,'vinci','code','brokeback','mountain'])\n",
    "\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc) :\n",
    "    stemmed_words = [stemmer.stem(w) for w in analyzer(doc)]\n",
    "    \n",
    "    non_stop_words = [word for word in stemmed_words if not word in stop_words_for_my_usecase]\n",
    "    return non_stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>harri</td>\n",
       "      <td>2093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>love</td>\n",
       "      <td>1883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>suck</td>\n",
       "      <td>1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>wa</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>like</td>\n",
       "      <td>1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>movi</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>awesom</td>\n",
       "      <td>1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>mission</td>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>imposs</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>hate</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    features  counts\n",
       "302    harri    2093\n",
       "413     love    1883\n",
       "791     suck    1484\n",
       "922       wa    1176\n",
       "399     like    1155\n",
       "446     movi    1149\n",
       "45    awesom    1130\n",
       "440  mission    1094\n",
       "350   imposs    1093\n",
       "304     hate     701"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "count_vectorizer = CountVectorizer(analyzer=stemmed_words,max_features=1000)\n",
    "\n",
    "identifiedfeatures_vector = count_vectorizer.fit(sentitraindf.text)\n",
    "train_identifiedfeatures = count_vectorizer.transform(sentitraindf.text)\n",
    "identifiedfeatures = identifiedfeatures_vector.get_feature_names()\n",
    "features_counts = np.sum(train_identifiedfeatures.toarray(),axis=0)\n",
    "\n",
    "featurescountdf = pd.DataFrame(dict(features=identifiedfeatures, counts = features_counts))\n",
    "featurescountdf.sort_values('counts',ascending= False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Document Vector matrix into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nlp_df = pd.DataFrame(train_identifiedfeatures.todense())\n",
    "train_nlp_df.columns = identifiedfeatures\n",
    "train_nlp_df['sentiment']= sentitraindf.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(train_identifiedfeatures,sentitraindf.sentiment,\n",
    "                                                    test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Naive-Bayes Model and predict on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "nb_classifier = BernoulliNB()\n",
    "nb_classifier.fit(train_X.toarray(),train_y)\n",
    "\n",
    "test_senti_predicted = nb_classifier.predict(test_X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Classification Report - Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       873\n",
      "           1       0.98      0.99      0.98      1203\n",
      "\n",
      "    accuracy                           0.98      2076\n",
      "   macro avg       0.98      0.98      0.98      2076\n",
      "weighted avg       0.98      0.98      0.98      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(test_y, test_senti_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "cm = metrics.confusion_matrix(test_y, test_senti_predicted)\n",
    "sns.heatmap(cm,annot=True, fmt='0.2f');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
