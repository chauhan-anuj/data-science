{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  spaCey Basics - Document, Tokens, Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = 'The match was very good. Sachin did not play well at all. The match was pathetic. Virat had a poor run. The computer shut down automatically'\n",
    "doc = nlp(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "was very good\n"
     ]
    }
   ],
   "source": [
    "span = doc[2:5]\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Index:  2\n",
      "Token Text:  was\n",
      "is Alphabetical:  True\n",
      "is Punctuation:  False\n",
      "is Number:  False\n",
      "Token Index:  3\n",
      "Token Text:  very\n",
      "is Alphabetical:  True\n",
      "is Punctuation:  False\n",
      "is Number:  False\n",
      "Token Index:  4\n",
      "Token Text:  good\n",
      "is Alphabetical:  True\n",
      "is Punctuation:  False\n",
      "is Number:  False\n"
     ]
    }
   ],
   "source": [
    "for token in span:\n",
    "    print(\"Token Index: \", token.i)\n",
    "    print(\"Token Text: \",token.text)\n",
    "    print(\"is Alphabetical: \",token.is_alpha)\n",
    "    print(\"is Punctuation: \",token.is_punct)\n",
    "    print(\"is Number: \",token.like_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCey Statistical Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flipkart ORG\n",
      "$25 billion MONEY\n",
      "2018 DATE\n",
      "India GPE\n",
      "Walmart PROPN nsubj acquired\n",
      "acquired VERB ROOT acquired\n",
      "Flipkart PROPN dobj acquired\n",
      "for ADP prep acquired\n",
      "$ SYM quantmod billion\n",
      "25 NUM compound billion\n",
      "billion NUM pobj for\n",
      "in ADP prep billion\n",
      "2018 NUM pobj in\n",
      ". PUNCT punct acquired\n",
      "This DET nsubj was\n",
      "was AUX ROOT was\n",
      "the DET det deal\n",
      "biggest ADJ amod deal\n",
      "acuqistion NOUN compound deal\n",
      "deal NOUN attr was\n",
      "in ADP prep deal\n",
      "India PROPN pobj in\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "sentence = 'Walmart acquired Flipkart for $25 billion in 2018. This was the biggest acuqistion deal in India'\n",
    "\n",
    "document = nlp(sentence)\n",
    "\n",
    "for ent in document.ents:\n",
    "    print(ent.text,ent.label_)\n",
    "    \n",
    "for token in document:\n",
    "    print(token.text,token.pos_,token.dep_,token.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Countries, cities, states'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('GPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adposition'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('ADP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New iPhone EVENT\n",
      "Apple ORG\n",
      "Missing entity: iPhone X\n"
     ]
    }
   ],
   "source": [
    "text = \"New iPhone X release date leaked as Apple reveals pre-orders by mistake\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the entities\n",
    "for ent in doc.ents:\n",
    "    # print the entity text and label\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "# Get the span for \"iPhone X\"\n",
    "iphone_x = doc[1:3]\n",
    "\n",
    "# Print the span text\n",
    "print('Missing entity:', iphone_x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: ['iPhone X']\n"
     ]
    }
   ],
   "source": [
    "text = \"New iPhone X release date leaked as Apple reveals pre-orders by mistake\"\n",
    "\n",
    "# Import the Matcher and initialize it with the shared vocabulary\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Create a pattern matching two tokens: \"iPhone\" and \"X\"\n",
    "pattern = [{'TEXT': 'iPhone'}, {'TEXT': 'X'}]\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "matcher.add('IPHONE_X_PATTERN', None, pattern)\n",
    "\n",
    "# Use the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "print('Matches:', [doc[start:end].text for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 3\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"After making the iOS update you won't notice a radical system-wide redesign: nothing like the aesthetic upheaval we got with iOS 7. Most of iOS 11's furniture remains the same as in iOS 10. But you will discover some tweaks once you delve a little deeper.\")\n",
    "\n",
    "# Write a pattern for full iOS versions (\"iOS 7\", \"iOS 11\", \"iOS 10\")\n",
    "pattern = [{'TEXT': 'iOS'}, {'IS_DIGIT': True}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add('IOS_VERSION_PATTERN', None, pattern)\n",
    "matches = matcher(doc)\n",
    "print('Total matches found:', len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 3\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"i downloaded Fortnite on my laptop and can't open the game at all. Help? so when I was downloading Minecraft, I got the Windows version where it is the '.zip' folder and I used the default program to unpack it... do I also need to download Winzip?\")\n",
    "\n",
    "# Write a pattern that matches a form of \"download\" plus proper noun\n",
    "pattern = [{'LEMMA': 'download'}, {'POS': 'PROPN'}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add('DOWNLOAD_THINGS_PATTERN', None, pattern)\n",
    "matches = matcher(doc)\n",
    "print('Total matches found:', len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16174960241667155899\n",
      "Fortnite\n"
     ]
    }
   ],
   "source": [
    "# Look up the hash for the word \"cat\"\n",
    "cat_hash = nlp.vocab.strings['Fortnite']\n",
    "print(cat_hash)\n",
    "\n",
    "# Look up the cat_hash to get the string\n",
    "cat_string = nlp.vocab.strings[cat_hash]\n",
    "print(cat_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
